#!/usr/bin/env python3
"""
KTransformers balance_serve åŠŸèƒ½é›†æˆæµ‹è¯•è„šæœ¬

è¿™ä¸ªè„šæœ¬æä¾›äº†å…¨é¢çš„ balance_serve åŠŸèƒ½æµ‹è¯•ï¼ŒåŒ…æ‹¬ï¼š
1. åŸºç¡€æ¨¡å—å¯¼å…¥æµ‹è¯•
2. åç«¯åˆå§‹åŒ–æµ‹è¯•
3. è°ƒåº¦å™¨åŠŸèƒ½æµ‹è¯•
4. ç®€å•çš„æ¨ç†æµ‹è¯•ï¼ˆå¦‚æœæœ‰æ¨¡å‹ï¼‰
5. æ€§èƒ½åŸºå‡†æµ‹è¯•
"""

import sys
import os
import time
import traceback
import tempfile
import json
from pathlib import Path
from typing import Dict, List, Optional, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

class BalanceServeTestSuite:
    """balance_serve åŠŸèƒ½æµ‹è¯•å¥—ä»¶"""
    
    def __init__(self):
        self.tests_run = 0
        self.tests_passed = 0
        self.tests_failed = 0
        self.test_results = []
        
    def log_info(self, message: str):
        print(f"[INFO] {message}")
        
    def log_success(self, message: str):
        print(f"[SUCCESS] âœ“ {message}")
        
    def log_error(self, message: str):
        print(f"[ERROR] âœ— {message}")
        
    def log_warn(self, message: str):
        print(f"[WARN] âš  {message}")
    
    def run_test(self, test_name: str, test_func, *args, **kwargs) -> bool:
        """è¿è¡Œå•ä¸ªæµ‹è¯•"""
        self.tests_run += 1
        self.log_info(f"è¿è¡Œæµ‹è¯• {self.tests_run}: {test_name}")
        
        try:
            start_time = time.time()
            result = test_func(*args, **kwargs)
            end_time = time.time()
            
            if result:
                self.log_success(f"{test_name} (è€—æ—¶: {end_time - start_time:.2f}s)")
                self.tests_passed += 1
                self.test_results.append({
                    'name': test_name,
                    'status': 'PASSED',
                    'duration': end_time - start_time,
                    'error': None
                })
                return True
            else:
                self.log_error(f"{test_name} - æµ‹è¯•è¿”å› False")
                self.tests_failed += 1
                self.test_results.append({
                    'name': test_name,
                    'status': 'FAILED',
                    'duration': end_time - start_time,
                    'error': 'Test returned False'
                })
                return False
                
        except Exception as e:
            end_time = time.time()
            error_msg = f"{str(e)}\n{traceback.format_exc()}"
            self.log_error(f"{test_name} - å¼‚å¸¸: {str(e)}")
            self.tests_failed += 1
            self.test_results.append({
                'name': test_name,
                'status': 'FAILED',
                'duration': end_time - start_time,
                'error': error_msg
            })
            return False
    
    def test_basic_imports(self) -> bool:
        """æµ‹è¯•åŸºç¡€æ¨¡å—å¯¼å…¥"""
        try:
            import ktransformers
            import torch
            import numpy as np
            
            self.log_info(f"KTransformers ç‰ˆæœ¬: {ktransformers.__version__}")
            self.log_info(f"PyTorch ç‰ˆæœ¬: {torch.__version__}")
            self.log_info(f"CUDA å¯ç”¨: {torch.cuda.is_available()}")
            
            return True
        except ImportError as e:
            self.log_error(f"åŸºç¡€æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def test_balance_serve_imports(self) -> bool:
        """æµ‹è¯• balance_serve ç›¸å…³æ¨¡å—å¯¼å…¥"""
        try:
            from ktransformers.server.backend.interfaces.balance_serve import BalanceServeInterface
            from ktransformers.server.backend.interfaces.balance_serve import BalanceServeThreadContext

            self.log_info("balance_serve æ ¸å¿ƒæ¨¡å—å¯¼å…¥æˆåŠŸ")
            return True
        except ImportError as e:
            self.log_error(f"balance_serve æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
            return False
    
    def test_optimization_rules(self) -> bool:
        """æµ‹è¯•ä¼˜åŒ–è§„åˆ™åŠ è½½"""
        try:
            import yaml
            
            rules_dir = project_root / "ktransformers" / "optimize" / "optimize_rules"
            if not rules_dir.exists():
                self.log_error(f"ä¼˜åŒ–è§„åˆ™ç›®å½•ä¸å­˜åœ¨: {rules_dir}")
                return False
            
            yaml_files = list(rules_dir.glob("*.yaml"))
            self.log_info(f"æ‰¾åˆ° {len(yaml_files)} ä¸ªä¼˜åŒ–è§„åˆ™æ–‡ä»¶")
            
            # æµ‹è¯•åŠ è½½ balance_serve ç›¸å…³çš„è§„åˆ™æ–‡ä»¶
            serve_rules = [f for f in yaml_files if 'serve' in f.name.lower()]
            if not serve_rules:
                self.log_warn("æœªæ‰¾åˆ° balance_serve ç›¸å…³çš„ä¼˜åŒ–è§„åˆ™æ–‡ä»¶")
                return True
            
            for rule_file in serve_rules[:3]:  # æµ‹è¯•å‰3ä¸ªæ–‡ä»¶
                with open(rule_file, 'r') as f:
                    rules = yaml.safe_load(f)
                self.log_info(f"æˆåŠŸåŠ è½½è§„åˆ™æ–‡ä»¶: {rule_file.name}")
            
            return True
        except Exception as e:
            self.log_error(f"ä¼˜åŒ–è§„åˆ™æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_backend_initialization(self) -> bool:
        """æµ‹è¯• balance_serve åç«¯åˆå§‹åŒ–"""
        try:
            from ktransformers.server.backend.interfaces.balance_serve import BalanceServeInterface

            # åˆ›å»ºä¸´æ—¶é…ç½®
            config = {
                'max_batch_size': 2,
                'cache_lens': 1024,
                'chunk_size': 128,
                'cpu_infer': 4,
                'model_path': '/tmp/dummy_model',  # è™šæ‹Ÿè·¯å¾„
                'gguf_path': '/tmp/dummy_gguf',    # è™šæ‹Ÿè·¯å¾„
            }

            # æ³¨æ„ï¼šè¿™é‡Œåªæµ‹è¯•ç±»çš„åˆ›å»ºï¼Œä¸è¿›è¡Œå®é™…çš„æ¨¡å‹åŠ è½½
            # å› ä¸ºæˆ‘ä»¬å¯èƒ½æ²¡æœ‰å®é™…çš„æ¨¡å‹æ–‡ä»¶
            backend_class = BalanceServeInterface
            self.log_info("BalanceServeInterface ç±»å¯ä»¥æ­£å¸¸è®¿é—®")

            return True
        except Exception as e:
            self.log_error(f"åç«¯åˆå§‹åŒ–æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_scheduler_functionality(self) -> bool:
        """æµ‹è¯•è°ƒåº¦å™¨åŸºç¡€åŠŸèƒ½"""
        try:
            # å°è¯•å¯¼å…¥è°ƒåº¦å™¨ç›¸å…³æ¨¡å—
            try:
                from ktransformers.server.balance_serve.sched_rpc import SchedulerClient
                self.log_info("SchedulerClient å¯¼å…¥æˆåŠŸ")
            except ImportError:
                self.log_warn("SchedulerClient å¯¼å…¥å¤±è´¥")

            # æ£€æŸ¥å…¶ä»–è°ƒåº¦å™¨ç›¸å…³æ¨¡å—
            try:
                from ktransformers.server.balance_serve.inference.query_manager import QueryManager
                self.log_info("QueryManager å¯¼å…¥æˆåŠŸ")
            except ImportError:
                self.log_warn("QueryManager å¯¼å…¥å¤±è´¥")

            return True
        except Exception as e:
            self.log_error(f"è°ƒåº¦å™¨åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_engine_functionality(self) -> bool:
        """æµ‹è¯•æ¨ç†å¼•æ“åŸºç¡€åŠŸèƒ½"""
        try:
            # å°è¯•å¯¼å…¥æ¨ç†å¼•æ“ç›¸å…³æ¨¡å—
            try:
                from ktransformers.server.balance_serve.inference.model_runner import ModelRunner
                self.log_info("ModelRunner å¯¼å…¥æˆåŠŸ")
            except ImportError:
                self.log_warn("ModelRunner å¯¼å…¥å¤±è´¥")

            # æ£€æŸ¥å…¶ä»–æ¨ç†ç›¸å…³æ¨¡å—
            try:
                from ktransformers.server.balance_serve.inference.forward_batch import ForwardBatchInput, ForwardBatchOutput
                self.log_info("ForwardBatch æ¨¡å—å¯¼å…¥æˆåŠŸ")
            except ImportError:
                self.log_warn("ForwardBatch æ¨¡å—å¯¼å…¥å¤±è´¥")

            return True
        except Exception as e:
            self.log_error(f"å¼•æ“åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_system_resources(self) -> bool:
        """æµ‹è¯•ç³»ç»Ÿèµ„æº"""
        try:
            import psutil
            
            # å†…å­˜æ£€æŸ¥
            mem = psutil.virtual_memory()
            total_gb = mem.total // (1024**3)
            available_gb = mem.available // (1024**3)
            
            self.log_info(f"ç³»ç»Ÿå†…å­˜: {total_gb}GB æ€»è®¡, {available_gb}GB å¯ç”¨")
            
            if total_gb < 16:
                self.log_warn("ç³»ç»Ÿå†…å­˜è¾ƒå°‘ï¼Œå¯èƒ½å½±å“å¤§æ¨¡å‹è¿è¡Œ")
            
            # CPU æ£€æŸ¥
            cpu_count = os.cpu_count()
            self.log_info(f"CPU æ ¸å¿ƒæ•°: {cpu_count}")
            
            # æ£€æŸ¥ AMX æ”¯æŒ
            try:
                with open('/proc/cpuinfo', 'r') as f:
                    cpuinfo = f.read()
                if 'amx' in cpuinfo:
                    self.log_success("æ£€æµ‹åˆ° AMX æŒ‡ä»¤æ”¯æŒ")
                else:
                    self.log_info("æœªæ£€æµ‹åˆ° AMX æŒ‡ä»¤æ”¯æŒ")
            except:
                self.log_warn("æ— æ³•æ£€æŸ¥ CPU ç‰¹æ€§")
            
            return True
        except Exception as e:
            self.log_error(f"ç³»ç»Ÿèµ„æºæ£€æŸ¥å¤±è´¥: {e}")
            return False
    
    def test_cuda_functionality(self) -> bool:
        """æµ‹è¯• CUDA åŠŸèƒ½"""
        try:
            import torch
            
            if not torch.cuda.is_available():
                self.log_warn("CUDA ä¸å¯ç”¨ï¼Œè·³è¿‡ CUDA æµ‹è¯•")
                return True
            
            device_count = torch.cuda.device_count()
            self.log_info(f"æ£€æµ‹åˆ° {device_count} ä¸ª CUDA è®¾å¤‡")
            
            for i in range(device_count):
                props = torch.cuda.get_device_properties(i)
                self.log_info(f"GPU {i}: {props.name}, {props.total_memory // (1024**2)}MB")
            
            # ç®€å•çš„ CUDA æ“ä½œæµ‹è¯•
            x = torch.randn(100, 100).cuda()
            y = torch.randn(100, 100).cuda()
            z = torch.matmul(x, y)
            
            self.log_success("CUDA åŸºç¡€æ“ä½œæµ‹è¯•é€šè¿‡")
            return True
            
        except Exception as e:
            self.log_error(f"CUDA åŠŸèƒ½æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def test_custom_flashinfer(self) -> bool:
        """æµ‹è¯• custom_flashinfer æ¨¡å—"""
        try:
            # å°è¯•å¯¼å…¥ custom_flashinfer
            import flashinfer
            self.log_success("custom_flashinfer å¯¼å…¥æˆåŠŸ")
            return True
        except ImportError:
            self.log_warn("custom_flashinfer æœªå®‰è£…æˆ–ä¸å¯ç”¨")
            return True  # ä¸æ˜¯è‡´å‘½é”™è¯¯
        except Exception as e:
            self.log_error(f"custom_flashinfer æµ‹è¯•å¤±è´¥: {e}")
            return False
    
    def generate_report(self) -> Dict[str, Any]:
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        success_rate = (self.tests_passed / self.tests_run * 100) if self.tests_run > 0 else 0
        
        report = {
            'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
            'summary': {
                'total_tests': self.tests_run,
                'passed': self.tests_passed,
                'failed': self.tests_failed,
                'success_rate': round(success_rate, 2)
            },
            'test_results': self.test_results,
            'system_info': {
                'python_version': sys.version,
                'platform': sys.platform,
            }
        }
        
        return report
    
    def run_all_tests(self):
        """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
        print("=" * 60)
        print("  KTransformers balance_serve åŠŸèƒ½æµ‹è¯•")
        print("=" * 60)
        
        # è¿è¡Œæ‰€æœ‰æµ‹è¯•
        tests = [
            ("åŸºç¡€æ¨¡å—å¯¼å…¥", self.test_basic_imports),
            ("balance_serve æ¨¡å—å¯¼å…¥", self.test_balance_serve_imports),
            ("ä¼˜åŒ–è§„åˆ™åŠ è½½", self.test_optimization_rules),
            ("åç«¯åˆå§‹åŒ–", self.test_backend_initialization),
            ("è°ƒåº¦å™¨åŠŸèƒ½", self.test_scheduler_functionality),
            ("å¼•æ“åŠŸèƒ½", self.test_engine_functionality),
            ("ç³»ç»Ÿèµ„æºæ£€æŸ¥", self.test_system_resources),
            ("CUDA åŠŸèƒ½", self.test_cuda_functionality),
            ("custom_flashinfer", self.test_custom_flashinfer),
        ]
        
        for test_name, test_func in tests:
            self.run_test(test_name, test_func)
            print()  # ç©ºè¡Œåˆ†éš”
        
        # ç”ŸæˆæŠ¥å‘Š
        report = self.generate_report()
        
        print("=" * 60)
        print("  æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 60)
        print(f"æ€»æµ‹è¯•æ•°: {report['summary']['total_tests']}")
        print(f"é€šè¿‡: {report['summary']['passed']}")
        print(f"å¤±è´¥: {report['summary']['failed']}")
        print(f"æˆåŠŸç‡: {report['summary']['success_rate']}%")
        
        # ä¿å­˜è¯¦ç»†æŠ¥å‘Š
        report_file = project_root / "test_report.json"
        with open(report_file, 'w') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        print(f"\nè¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
        # è¿”å›æˆåŠŸçŠ¶æ€
        return self.tests_failed == 0


def main():
    """ä¸»å‡½æ•°"""
    test_suite = BalanceServeTestSuite()
    success = test_suite.run_all_tests()
    
    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼balance_serve åŠŸèƒ½æ­£å¸¸ã€‚")
        sys.exit(0)
    else:
        print(f"\nâŒ {test_suite.tests_failed} ä¸ªæµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚")
        sys.exit(1)


if __name__ == "__main__":
    main()
